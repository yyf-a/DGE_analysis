---
title: "DESeq2 Notebook"
output: html_notebook
---

## set-up
```{r}
# load data
library("pasilla")
# load package
library("DESeq2")
```


### load the count matrix file
To use `DESeqDataSetFromMatrix`, the user should provide the counts matrix, the information about the samples (the columns of the count matrix) as a DataFrame or data.frame, and the design formula.
```{r}
pasCts <- system.file("extdata",
                      "pasilla_gene_counts.tsv",
                      package="pasilla", mustWork=TRUE)
pasAnno <- system.file("extdata",
                       "pasilla_sample_annotation.csv",
                       package="pasilla", mustWork=TRUE)
cts <- as.matrix(read.csv(pasCts,sep="\t",row.names="gene_id"))
coldata <- read.csv(pasAnno, row.names=1)
coldata <- coldata[,c("condition","type")]
coldata$condition <- factor(coldata$condition)
coldata$type <- factor(coldata$type)
```
- `cts`: count matrix
- `coldtate`: The design matrix: The design formula should have all of the factors in your metadata that account for major sources of variation in your data. The last factor entered in the formula should be the condition of interest.
`design <- ~ type + condiction`

It is absolutely critical that the columns of the count matrix and the rows of the column data (information about samples) are in the same order. DESeq2 will not make guesses as to which column of the count matrix belongs to which row of the column data, these must be provided to DESeq2 already in consistent order.

we need to re-arrange one or the other so that they are consistent in terms of sample order 
```{r}
rownames(coldata) <- sub("fb", "", rownames(coldata))
all(rownames(coldata) %in% colnames(cts))
all(rownames(coldata) == colnames(cts))
cts <- cts[, rownames(coldata)]
all(rownames(coldata) == colnames(cts))
```

## proprocessing data
First we create a `DESeqDataSet` as we did in the ‘Count normalization’ and specify the location of our raw counts and metadata, and input our design formula:
```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ condition)
dds
```

### filtering data

```{r}
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]
```

### justify reference level
Similar to Limma-voom method, R will choose a reference level for factors based on alphabetical order by default. There are two solutions: 
1. you can either explicitly tell results which comparison to make using the contrast argument (as shown Limma-voom file),
2. you can explicitly set the factors levels. In order to see the change of reference levels reflected in the results names, you need to either run `DESeq` or `nbinomWaldTest`/`nbinomLRT` after the re-leveling operation. Setting the factor levels can be done in two ways, either using factor:

```{r}
dds$condition <- factor(dds$condition, levels = c("untreated","treated"))
```

or 
```{r}
dds$condition <- relevel(dds$condition, ref = "untreated")
```

## DGE
Everything from normalization to linear modeling was carried out by the use of a single function! 
NOTE: There are individual functions available in DESeq2 that would allow us to carry out each step in the workflow in a step-wise manner, rather than a single call. We demonstrated one example when generating size factors to create a normalized matrix. By calling DESeq(), the individual functions for each step are run for you.

```{r}
## Run analysis
dds_result <- DESeq(dds)
res <- results(dds_result)
res
```

The log fold change reflects the results of treated vs untreated.

DESeq2 differential gene expression analysis workflow is shown below. Here we walk through the function in analysis workflow one by one. 
![DESeq2 differential gene expression analysis workflow](deseq2_workflow_separate.png)

### Step 1: Estimate size factors

This step is to achieve the normalization. To normalize the count data, DESeq2 calculates size factors for each sample using the median of ratios. 
```{r}
dds <- estimateSizeFactors(dds)
sizeFactors(dds)
```
### Step 2: Estimate gene-wise dispersion
DESeq2 assumes that genes with similar expression levels have similar dispersion. Thus, DESeq2 shares information across genes to generate more accurate estimates of variation based on the mean expression level of the gene.

### Step 3: Fit curve to gene-wise dispersion estimates


```{r}
dds <- estimateDispersions(dds)
```
```{r}
plotDispEsts(dds)
```

```{r}
# Generate the results table
res <- results(dds_result)

# Create the MA plot using DESeq2's 'plotMA' function
plotMA(res, main="MA Plot", ylim=c(-2, 2))
```

he `DESeq()` function in `DESeq2` runs the main pipeline for differential gene expression analysis, which includes normalization, dispersion estimation, and statistical testing for differential expression. However, the `DESeq()` function does not perform LFC shrinkage.
The log2 fold change shrinkage is performed separately using the `lfcShrink()` function after running the main DESeq2 pipeline. Shrinkage methods, such as "apeglm" or "ashr," help improve the stability of LFC estimates, especially for genes with low counts or high variance.
You might see a trend in the data points that appears to show some degree of shrinkage, even if you haven't explicitly applied the `lfcShrink()` function. This is because `DESeq2` applies a small amount of LFC shrinkage internally as part of the testing procedure, which can be seen in the MA plot. However, this internal shrinkage is not as robust as the one provided by the `lfcShrink()` function, which is why it's recommended to use `lfcShrink()` for improved LFC estimates.

### Step 4: Shrink gene-wise dispersion estimates toward the values predicted by the curve

Here we demonstate the  Log fold change shrinkage for visualization and ranking
The estimation of fold changes can be affected by various factors, such as low counts, high variability, or small sample sizes. This can result in noisy or unstable fold change estimates, particularly for lowly expressed genes.
Log fold change shrinkage aims to address these issues by borrowing information across all genes to adjust individual fold change estimates. 


```{r}
resLFC <- lfcShrink(dds_result, coef="condition_treated_vs_untreated", type="apeglm")
resLFC
```
he options for type are:

- `apeglm` is the adaptive t prior shrinkage estimator from the `apeglm` package (Zhu, Ibrahim, and Love 2018). 
- `ashr` is the adaptive shrinkage estimator from the `ashr` package (Stephens 2016). Here DESeq2 uses the `ashr` option to fit a mixture of Normal distributions to form the prior, with method="shrinkage".
- `normal` is the the original DESeq2 shrinkage estimator, an adaptive Normal distribution as prior.

```{r}
# plot of MA after shrinkage
plotMA(resLFC, main="MA Plot after LFC shrinakge", ylim=c(-2, 2))
```
The results are so much better, especially for low expression counts. 


#### comparing the results of three shrink methods

```{r}
# because we are interested in treated vs untreated, we set 'coef=2'
resNorm <- lfcShrink(dds_result, coef=2, type="normal")
resAsh <- lfcShrink(dds_result, coef=2, type="ashr")

par(mfrow=c(1,3), mar=c(4,4,2,1))
xlim <- c(1,1e5); ylim <- c(-3,3)
plotMA(resLFC, xlim=xlim, ylim=ylim, main="apeglm")
plotMA(resNorm, xlim=xlim, ylim=ylim, main="normal")
plotMA(resAsh, xlim=xlim, ylim=ylim, main="ashr")
```
### calculate p-value

the results function automatically performs independent filtering based on the mean of normalized counts for each gene, optimizing the number of genes which will have an adjusted p value below a given FDR cutoff, alpha.
```{r}
res05 <- results(dds_result, alpha=0.05)
summary(res05)
```




# reference
- https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#altshrink
- https://bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html
- https://hbctraining.github.io/DGE_workshop/lessons/04_DGE_DESeq2_analysis.html


